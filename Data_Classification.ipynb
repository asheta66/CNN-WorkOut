{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "MNIST_grid_search_cv_exercise.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asheta66/CNN-WorkOut/blob/main/Data_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdz5jr0WDNJy"
      },
      "source": [
        "<h2 align='center' style='color:blue'>Finding best model and hyper parameters for sklearn digits dataset classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cbrvpCHDp_z"
      },
      "source": [
        "For digits dataset in sklearn.dataset, please try following classifiers and find out the one that gives best performance. Also find the optimal parameters for that classifier.\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3w6soYUDNJ1"
      },
      "source": [
        "from sklearn import datasets\n",
        "digits = datasets.load_digits()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOxLA6xLDNJ3"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0LPs5BdDNJ3"
      },
      "source": [
        "model_params = {\n",
        "    'svm': {\n",
        "        'model': svm.SVC(gamma='auto'),\n",
        "        'params' : {\n",
        "            'C': [1,10,20],\n",
        "            'kernel': ['rbf','linear']\n",
        "        }  \n",
        "    },\n",
        "    'random_forest': {\n",
        "        'model': RandomForestClassifier(),\n",
        "        'params' : {\n",
        "            'n_estimators': [1,5,10]\n",
        "        }\n",
        "    },\n",
        "    'logistic_regression' : {\n",
        "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
        "        'params': {\n",
        "            'C': [1,5,10]\n",
        "        }\n",
        "    },\n",
        "    'naive_bayes_gaussian': {\n",
        "        'model': GaussianNB(),\n",
        "        'params': {}\n",
        "    },\n",
        "    'naive_bayes_multinomial': {\n",
        "        'model': MultinomialNB(),\n",
        "        'params': {}\n",
        "    },\n",
        "    'decision_tree': {\n",
        "        'model': DecisionTreeClassifier(),\n",
        "        'params': {\n",
        "            'criterion': ['gini','entropy'],\n",
        "            \n",
        "        }\n",
        "    }     \n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ED5jtTEcDNJ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "e3122597-578d-43b7-b193-1cf6acbe8e0f"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import pandas as pd\n",
        "scores = []\n",
        "\n",
        "for model_name, mp in model_params.items():\n",
        "    clf =  GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
        "    clf.fit(digits.data, digits.target)\n",
        "    scores.append({\n",
        "        'model': model_name,\n",
        "        'best_score': clf.best_score_,\n",
        "        'best_params': clf.best_params_\n",
        "    })\n",
        "    \n",
        "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>best_score</th>\n",
              "      <th>best_params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>svm</td>\n",
              "      <td>0.947697</td>\n",
              "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>random_forest</td>\n",
              "      <td>0.900975</td>\n",
              "      <td>{'n_estimators': 10}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>logistic_regression</td>\n",
              "      <td>0.922114</td>\n",
              "      <td>{'C': 1}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>naive_bayes_gaussian</td>\n",
              "      <td>0.806928</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>naive_bayes_multinomial</td>\n",
              "      <td>0.870350</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>decision_tree</td>\n",
              "      <td>0.810823</td>\n",
              "      <td>{'criterion': 'entropy'}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     model  best_score                   best_params\n",
              "0                      svm    0.947697  {'C': 1, 'kernel': 'linear'}\n",
              "1            random_forest    0.900975          {'n_estimators': 10}\n",
              "2      logistic_regression    0.922114                      {'C': 1}\n",
              "3     naive_bayes_gaussian    0.806928                            {}\n",
              "4  naive_bayes_multinomial    0.870350                            {}\n",
              "5            decision_tree    0.810823      {'criterion': 'entropy'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz9L44GZDNJ5"
      },
      "source": [
        "**For me the winner is svm (C=1, kernel=linear) with 94.93% score. It could be different for you as I have limited my parameters to be certain values only**"
      ]
    }
  ]
}